{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b31de2a-10e6-4c1c-9c83-9c2de8ca92ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "import json\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger, \n",
    "    ParameterFloat, \n",
    "    ParameterString, \n",
    "    ParameterBoolean\n",
    ")\n",
    "\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput, \n",
    "    ProcessingOutput, \n",
    "    ScriptProcessor\n",
    ")\n",
    "\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep, \n",
    "    TrainingStep, \n",
    "    CreateModelStep\n",
    ")\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger, \n",
    "    ParameterFloat, \n",
    "    ParameterString, \n",
    "    ParameterBoolean\n",
    ")\n",
    "from sagemaker.workflow.clarify_check_step import (\n",
    "    ModelBiasCheckConfig, \n",
    "    ClarifyCheckStep, \n",
    "    ModelExplainabilityCheckConfig\n",
    ")\n",
    "from sagemaker import Model\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.conditions import (\n",
    "    ConditionGreaterThan,\n",
    "    ConditionGreaterThanOrEqualTo\n",
    ")\n",
    "\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db97b1-7482-43b6-9e75-58f88c0f990c",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca27a761-7392-4723-a349-83ae729978a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::567821811420:role/service-role/AmazonSageMaker-ExecutionRole-20230619T084765\n"
     ]
    }
   ],
   "source": [
    "# Get some variables you need to interact with SageMaker service\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "bucket_prefix = \"from-idea-to-prod/xgboost\"  \n",
    "sm_session = sagemaker.Session()\n",
    "sm_client = boto_session.client(\"sagemaker\")\n",
    "sm_role = sagemaker.get_execution_role()\n",
    "\n",
    "initialized = True\n",
    "\n",
    "print(sm_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e38ec91f-1aa0-44b6-9489-bb7a8ce5a102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store some variables to keep the value between the notebooks\n",
    "# %store bucket_name\n",
    "# %store bucket_prefix\n",
    "# %store sm_role\n",
    "# %store region\n",
    "# %store initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4932f40-e70d-4d64-bd23-da7a6d3172a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker domain id: d-ivd5gnez0yil\n"
     ]
    }
   ],
   "source": [
    "NOTEBOOK_METADATA_FILE = \"/opt/ml/metadata/resource-metadata.json\"\n",
    "domain_id = None\n",
    "\n",
    "if os.path.exists(NOTEBOOK_METADATA_FILE):\n",
    "    with open(NOTEBOOK_METADATA_FILE, \"rb\") as f:\n",
    "        domain_id = json.loads(f.read()).get('DomainId')\n",
    "        print(f\"SageMaker domain id: {domain_id}\")\n",
    "\n",
    "# %store domain_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f014ce-bfee-45ec-94b0-783847cada9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set names of pipeline objects\n",
    "project = \"solar1\"\n",
    "\n",
    "pipeline_name = f\"{project}-pipeline\"\n",
    "pipeline_model_name = f\"{project}-model-reg\"\n",
    "model_package_group_name = f\"{project}-model-group\"\n",
    "endpoint_config_name = f\"{project}-endpoint-config\"\n",
    "endpoint_name = f\"{project}-endpoint\"\n",
    "\n",
    "# Set instance types and counts\n",
    "process_instance_type = \"ml.c5.xlarge\"\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "# Set S3 urls for processed data\n",
    "train_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/train\"\n",
    "validation_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/validation\"\n",
    "test_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/test\"\n",
    "baseline_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/baseline\"\n",
    "\n",
    "evaluation_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/evaluation\"\n",
    "prediction_baseline_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/prediction_baseline\"\n",
    "\n",
    "output_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "261541f6-eea0-47f7-bd0d-289fcb640bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#store the variable\n",
    "# %store train_s3_url\n",
    "# %store validation_s3_url\n",
    "# %store test_s3_url\n",
    "# %store baseline_s3_url\n",
    "# %store model_package_group_name\n",
    "# %store evaluation_s3_url\n",
    "# %store prediction_baseline_s3_url\n",
    "# %store output_s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5442f6-b0c6-469d-af61-15786d11ab76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set instance types and counts\n",
    "process_instance_type = \"ml.c5.xlarge\"\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6351e3c1-00d6-4c4f-b9e1-ba3187e1ac95",
   "metadata": {},
   "source": [
    "## Read data and upload it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19b48a7-58d4-4d91-bbd4-6a57294c704c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read data and save it in pandas dataframe\n",
    "df_gen1 = pd.read_csv(\"data/Plant_1_Generation_Data.csv\")\n",
    "df_gen2 = pd.read_csv(\"data/Plant_2_Generation_Data.csv\")\n",
    "\n",
    "df_weather1 = pd.read_csv(\"data/Plant_1_Weather_Sensor_Data.csv\")\n",
    "df_weather2 = pd.read_csv(\"data//Plant_2_Weather_Sensor_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccbba575-e0b8-4fb1-9b09-cb70e1c5a886",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>PLANT_ID</th>\n",
       "      <th>SOURCE_KEY</th>\n",
       "      <th>DC_POWER</th>\n",
       "      <th>AC_POWER</th>\n",
       "      <th>DAILY_YIELD</th>\n",
       "      <th>TOTAL_YIELD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-05-2020 00:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6259559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-05-2020 00:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1IF53ai7Xc0U56Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6183645.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-05-2020 00:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>3PZuoBAID5Wc2HD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6987759.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-05-2020 00:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>7JYdWkrLSPkdwr4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7602960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-05-2020 00:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>McdE0feGgRqW7Ca</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7158964.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE_TIME  PLANT_ID       SOURCE_KEY  DC_POWER  AC_POWER  \\\n",
       "0  15-05-2020 00:00   4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "1  15-05-2020 00:00   4135001  1IF53ai7Xc0U56Y       0.0       0.0   \n",
       "2  15-05-2020 00:00   4135001  3PZuoBAID5Wc2HD       0.0       0.0   \n",
       "3  15-05-2020 00:00   4135001  7JYdWkrLSPkdwr4       0.0       0.0   \n",
       "4  15-05-2020 00:00   4135001  McdE0feGgRqW7Ca       0.0       0.0   \n",
       "\n",
       "   DAILY_YIELD  TOTAL_YIELD  \n",
       "0          0.0    6259559.0  \n",
       "1          0.0    6183645.0  \n",
       "2          0.0    6987759.0  \n",
       "3          0.0    7602960.0  \n",
       "4          0.0    7158964.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23bc5cf2-8d7f-449d-a83a-cc5217f5501b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell to import or install the Data Wrangler widget to show automatic visualization and generate code to fix data quality issues\n",
    "try:\n",
    "    import sagemaker_datawrangler\n",
    "except ImportError:\n",
    "    !pip install --upgrade sagemaker-datawrangler\n",
    "    import sagemaker_datawrangler\n",
    "\n",
    "# Display Pandas DataFrame to view the widget: df, display(df), df.sample()... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04117339-8b30-46da-84ef-e1eb30c5aae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_bucket failed: s3://sagemaker-eu-central-1-d48 An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "#create S3 bucket \n",
    "!aws s3 mb s3://sagemaker-eu-central-1-d48\n",
    "bucket_name='sagemaker-eu-central-1-d48'\n",
    "bucket_prefix='solar1/linerreg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8d50f9-0ecf-494e-b01d-457f9f84eb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload complete.\n"
     ]
    }
   ],
   "source": [
    "#Upload data to S3 bucket\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Upload Plant_1_Generation_Data.csv\n",
    "s3.upload_file(\"data/Plant_1_Generation_Data.csv\", bucket_name, \"input/Plant_1_Generation_Data.csv\")\n",
    "\n",
    "# Upload Plant_2_Generation_Data.csv\n",
    "s3.upload_file(\"data/Plant_2_Generation_Data.csv\", bucket_name, \"input/Plant_2_Generation_Data.csv\")\n",
    "\n",
    "# Upload Plant_1_Weather_Sensor_Data.csv\n",
    "s3.upload_file(\"data/Plant_1_Weather_Sensor_Data.csv\", bucket_name, \"input/Plant_1_Weather_Sensor_Data.csv\")\n",
    "\n",
    "# Upload Plant_2_Weather_Sensor_Data.csv\n",
    "s3.upload_file(\"data/Plant_2_Weather_Sensor_Data.csv\", bucket_name, \"input/Plant_2_Weather_Sensor_Data.csv\")\n",
    "\n",
    "print(\"Upload complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "816e26b2-4065-4ccf-acac-9a3dd940e434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    input_s3_url\n",
    "except NameError:      \n",
    "    # If input_s3_url is not defined, upload the datasets to S3 and store the paths\n",
    "    input_s3_url_gen1 = sagemaker.Session().upload_data(\n",
    "        path=\"data/Plant_1_Generation_Data.csv\",\n",
    "        bucket=bucket_name,\n",
    "        key_prefix=f\"{bucket_prefix}/input\"\n",
    "    )\n",
    "    input_s3_url_gen2 = sagemaker.Session().upload_data(\n",
    "        path=\"data/Plant_2_Generation_Data.csv\",\n",
    "        bucket=bucket_name,\n",
    "        key_prefix=f\"{bucket_prefix}/input\"\n",
    "    )\n",
    "    input_s3_url_weather1 = sagemaker.Session().upload_data(\n",
    "        path=\"data/Plant_1_Weather_Sensor_Data.csv\",\n",
    "        bucket=bucket_name,\n",
    "        key_prefix=f\"{bucket_prefix}/input\"\n",
    "    )\n",
    "    input_s3_url_weather2 = sagemaker.Session().upload_data(\n",
    "        path=\"data/Plant_2_Weather_Sensor_Data.csv\",\n",
    "        bucket=bucket_name,\n",
    "        key_prefix=f\"{bucket_prefix}/input\"\n",
    "    )\n",
    "    print(\"Upload complete.\")\n",
    "\n",
    "    # %store input_s3_url_gen1\n",
    "    # %store input_s3_url_gen2\n",
    "    # %store input_s3_url_weather1\n",
    "    # %store input_s3_url_weather2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd941676-a844-47df-8d32-653ac2def6c4",
   "metadata": {},
   "source": [
    "## Create pipeline\n",
    "### Setup pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8713d926-5a17-4c83-9700-570e0d5c2d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set processing instance type\n",
    "process_instance_type_param = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=process_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance type\n",
    "train_instance_type_param = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=train_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance count\n",
    "train_instance_count_param = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value=train_instance_count\n",
    ")\n",
    "\n",
    "# Set model approval param\n",
    "model_approval_status_param = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "# Minimal threshold for model performance on the test dataset\n",
    "test_score_threshold_param = ParameterFloat(\n",
    "    name=\"TestScoreThreshold\", \n",
    "    default_value=0.75\n",
    ")\n",
    "\n",
    "# Set S3 url for input dataset\n",
    "input_s3_url_param_g1 = ParameterString(\n",
    "    name=\"InputDataUrgen1\",\n",
    "    default_value=input_s3_url_gen1,\n",
    ")\n",
    "\n",
    "input_s3_url_param_g2 = ParameterString(\n",
    "    name=\"InputDataUrgen2\",\n",
    "    default_value=input_s3_url_gen2,\n",
    ")\n",
    "\n",
    "input_s3_url_param_w1= ParameterString(\n",
    "    name=\"InputDataUrweather1\",\n",
    "    default_value=input_s3_url_weather1,\n",
    ")\n",
    "\n",
    "input_s3_url_param_w2 = ParameterString(\n",
    "    name=\"InputDataUrweather2\",\n",
    "    default_value=input_s3_url_weather2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce632e-03a0-4933-b148-e7a65c644117",
   "metadata": {},
   "source": [
    "### Build the pipeline steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85338988-5ea4-4053-9890-b411abc13d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = PipelineSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1acef9d-1538-4c33-8cc5-1c5a891f9392",
   "metadata": {},
   "source": [
    "#### Processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "761ed590-ae36-4a64-a1a1-efe1abfae767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_gen1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f9b26621e8a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_gen1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_gen1' is not defined"
     ]
    }
   ],
   "source": [
    "df_gen1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0729c40-50bc-4582-be7a-1e66dda57cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def _parse_args():\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Data, model, and output directories\n",
    "    # model_dir is always passed in from SageMaker. By default, this is an S3 path under the default bucket.\n",
    "    parser.add_argument('--filepath', type=str, default='/opt/ml/processing/input/')\n",
    "    parser.add_argument('--filename', type=str, default='input')\n",
    "    parser.add_argument('--outputpath', type=str, default='/opt/ml/processing/output/')\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Process arguments\n",
    "    args, _ = _parse_args()\n",
    "    \n",
    "    target_col = \"DC_POWER\"\n",
    "    \n",
    "    # Load data\n",
    "    df_gen1 = pd.read_csv(os.path.join(args.filepath, 'Plant_1_Generation_Data.csv'))\n",
    "    df_gen2 = pd.read_csv(os.path.join(args.filepath, 'Plant_2_Generation_Data.csv'))\n",
    "    df_weather1 = pd.read_csv(os.path.join(args.filepath, 'Plant_1_Weather_Sensor_Data.csv'))\n",
    "    df_weather2 = pd.read_csv(os.path.join(args.filepath, 'Plant_2_Weather_Sensor_Data.csv'))\n",
    "    \n",
    "    # Adjust datetime format\n",
    "    df_gen1['DATE_TIME'] = pd.to_datetime(df_gen1['DATE_TIME'], format='%d-%m-%Y %H:%M')\n",
    "    df_weather1['DATE_TIME'] = pd.to_datetime(df_weather1['DATE_TIME'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df_gen2['DATE_TIME'] = pd.to_datetime(df_gen2['DATE_TIME'], format='%d-%m-%Y %H:%M')\n",
    "    df_weather2['DATE_TIME'] = pd.to_datetime(df_weather2['DATE_TIME'], format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Drop unnecessary columns and merge dataframes\n",
    "    df_plant1 = pd.merge(\n",
    "        df_gen1.drop(columns=['PLANT_ID','AC_POWER','TOTAL_YIELD']),\n",
    "        df_weather1.drop(columns=['PLANT_ID', 'SOURCE_KEY']),\n",
    "        on='DATE_TIME'\n",
    "    )\n",
    "    \n",
    "    df_plant2 = pd.merge(\n",
    "        df_gen2.drop(columns=['PLANT_ID','AC_POWER','TOTAL_YIELD']),\n",
    "        df_weather2.drop(columns=['PLANT_ID', 'SOURCE_KEY']),\n",
    "        on='DATE_TIME'\n",
    "    )\n",
    "    \n",
    "    combined_plant = pd.concat([df_plant1, df_plant2])\n",
    "    \n",
    "    # adding separate time and date columns\n",
    "    combined_plant[\"DATE\"] = pd.to_datetime(combined_plant[\"DATE_TIME\"]).dt.date # add new column with date\n",
    "    combined_plant[\"TIME\"] = pd.to_datetime(combined_plant[\"DATE_TIME\"]).dt.time # add new column with time\n",
    "\n",
    "    # add hours and minutes for ml models\n",
    "    combined_plant['HOURS'] = pd.to_datetime(combined_plant['TIME'],format='%H:%M:%S').dt.hour\n",
    "    combined_plant['MINUTES'] = pd.to_datetime(combined_plant['TIME'],format='%H:%M:%S').dt.minute\n",
    "    combined_plant['MINUTES_PASS'] = df_plant1['MINUTES'] + combined_plant['HOURS']*60\n",
    "    \n",
    "    \n",
    "    # Shuffle and split the dataset\n",
    "    train_data, validation_data, test_data = np.split(\n",
    "        combined_plant.sample(frac=1, random_state=1729),\n",
    "        [int(0.7 * len(df_plant)), int(0.9 * len(df_plant))],\n",
    "    )\n",
    "\n",
    "    print(f\"Data split > train:{train_data.shape} | validation:{validation_data.shape} | test:{test_data.shape}\")\n",
    "    \n",
    "    # Save datasets locally\n",
    "    train_data.to_csv(os.path.join(args.outputpath, 'train/train.csv'), index=False, header=False)\n",
    "    validation_data.to_csv(os.path.join(args.outputpath, 'validation/validation.csv'), index=False, header=False)\n",
    "    test_data[target_col].to_csv(os.path.join(args.outputpath, 'test/test_y.csv'), index=False, header=False)\n",
    "    test_data.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'test/test_x.csv'), index=False, header=False)\n",
    "\n",
    "\n",
    "    # Save the baseline dataset for model monitoring\n",
    "    combined_plant.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'baseline/baseline.csv'), index=False, header=False)\n",
    "    \n",
    "    print(\"## Processing complete. Exiting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d3fede-8995-458a-9880-0e69b1dea719",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SKLearnProcessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2c6006475964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create SKLearnProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m sklearn_processor = SKLearnProcessor(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mframework_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.23-1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrole\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msm_role\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_instance_type_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SKLearnProcessor' is not defined"
     ]
    }
   ],
   "source": [
    "# Create SKLearnProcessor\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=sm_role,\n",
    "    instance_type=process_instance_type_param.default_value,\n",
    "    instance_count=1,\n",
    "    base_job_name=f\"{pipeline_name}/preprocess\",\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "\n",
    "# Define processing inputs\n",
    "processing_inputs = [\n",
    "    ProcessingInput(source=input_s3_url_param_g1, destination=\"/opt/ml/processing/input\"),\n",
    "    ProcessingInput(source=input_s3_url_param_g2, destination=\"/opt/ml/processing/input\"),\n",
    "    ProcessingInput(source=input_s3_url_param_w1, destination=\"/opt/ml/processing/input\"),\n",
    "    ProcessingInput(source=input_s3_url_param_w2, destination=\"/opt/ml/processing/input\"),\n",
    "]\n",
    "\n",
    "# Define processing outputs\n",
    "processing_outputs = [\n",
    "    ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/output/train\", destination=train_s3_url),\n",
    "    ProcessingOutput(output_name=\"validation_data\", source=\"/opt/ml/processing/output/validation\", destination=validation_s3_url),\n",
    "    ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/output/test\", destination=test_s3_url),\n",
    "    ProcessingOutput(output_name=\"baseline_data\", source=\"/opt/ml/processing/output/baseline\", destination=baseline_s3_url),\n",
    "]\n",
    "\n",
    "# Run the SKLearnProcessor\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=processing_inputs,\n",
    "    outputs=processing_outputs,\n",
    "    code='preprocessing.py',\n",
    "    # arguments = ['arg1', 'arg2'],\n",
    ")\n",
    "\n",
    "# Define processing step\n",
    "step_process = ProcessingStep(\n",
    "    name=f\"{pipeline_name}-preprocess-data\",\n",
    "    step_args=processor_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85447535-3c81-44f8-8ab9-d4e577ce0b0e",
   "metadata": {},
   "source": [
    "#### Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5fd44b0-bba3-4fd3-9ac0-9e3084c0a343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LinearRegression_image_uri = sagemaker.image_uris.retrieve(framework='linear-learner',region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "126939a1-d7e4-4438-8218-5618d539f8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate a Linear Learner estimator object\n",
    "estimator = Estimator(\n",
    "    image_uri=LinearRegression_image_uri,\n",
    "    role=get_execution_role(),\n",
    "    instance_type=train_instance_type_param,\n",
    "    instance_count=train_instance_count_param,\n",
    "    output_path=output_s3_url,\n",
    "    sagemaker_session=session,\n",
    "    base_job_name=f\"{pipeline_name}/train\",\n",
    ")\n",
    "\n",
    "# Define algorithm hyperparameters\n",
    "estimator.set_hyperparameters(\n",
    "    predictor_type='regressor',  # Set the predictor type to 'regressor' for linear regression\n",
    "    feature_dim=5,  # Specify the number of input features\n",
    "    epochs=100,  # Number of training epochs\n",
    "    mini_batch_size=32,  # Mini-batch size for training\n",
    "    learning_rate=0.1,  # Learning rate for the optimizer\n",
    "    normalize_data='true',  # Normalize the input features\n",
    "    loss='squared_loss',  # Loss function for linear regression\n",
    "    early_stopping_patience=10,  # Patience for early stopping\n",
    "    early_stopping_tolerance=0.001,  # Tolerance for early stopping\n",
    "    early_stopping_enabled=True,  # Enable early stopping\n",
    ")\n",
    "\n",
    "# Define training inputs\n",
    "training_inputs = {\n",
    "    \"train\": TrainingInput(\n",
    "        s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train_data\"].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "    \"validation\": TrainingInput(\n",
    "        s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation_data\"].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Fit the estimator to the training data\n",
    "training_args = estimator.fit(training_inputs)\n",
    "\n",
    "# Define the training step\n",
    "step_train = TrainingStep(\n",
    "    name=f\"{pipeline_name}-train\",\n",
    "    step_args=training_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d6f3bb-3380-4b6f-a054-6119d632b4e0",
   "metadata": {},
   "source": [
    "#### Evaluation step\n",
    "Create a model evaluation script to check if the model performance meets the specified threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c806049-c7b7-4225-8706-b3a59a862481",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile evaluation.py\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "if __name__ == \"__main__\":   \n",
    "    \n",
    "    # All paths are local for the processing container\n",
    "    model_path = \"/opt/ml/processing/model/model.tar.gz\"\n",
    "    test_x_path = \"/opt/ml/processing/test/test_x.csv\"\n",
    "    test_y_path = \"/opt/ml/processing/test/test_y.csv\"\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    output_prediction_path = \"/opt/ml/processing/output/\"\n",
    "        \n",
    "    # Read model tar file\n",
    "    with tarfile.open(model_path, \"r:gz\") as t:\n",
    "        t.extractall(path=\".\")\n",
    "    \n",
    "    # Load model\n",
    "    model = linear.Booster()\n",
    "    model.load_model(\"linear-model\")\n",
    "    \n",
    "    # Read test data\n",
    "    X_test = pd.read_csv(test_x_path, header=None).values\n",
    "    y_test = pd.read_csv(test_y_path, header=None).to_numpy()\n",
    "\n",
    "    # Run predictions\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    \n",
    "    # Calculate R2 score\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "            \"rmse\": {\n",
    "                \"value\": rmse,\n",
    "            },\n",
    "            \"r2_score\": {\n",
    "                \"value\": r2,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Save evaluation report\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    with open(f\"{output_dir}/evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))\n",
    "    \n",
    "    # Save prediction baseline file - we need it later for the model quality monitoring\n",
    "    pd.DataFrame({\"prediction\": predictions,\n",
    "                  \"label\": y_test.squeeze()}\n",
    "                ).to_csv(os.path.join(output_prediction_path, 'prediction_baseline/prediction_baseline.csv'), index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b39b676-6fcd-4adb-8e88-a1aa6df7ddaa",
   "metadata": {},
   "source": [
    "Create a processor to run the evaluation script and construct the evaluation step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f580b00-6031-4204-a098-caa99bcefee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "script_processor = ScriptProcessor(\n",
    "    image_uri=LinearRegression_image_uri,\n",
    "    role=sm_role,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=process_instance_type_param,\n",
    "    instance_count=1,\n",
    "    base_job_name=f\"{pipeline_name}/evaluate\",\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "......................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30518ca-e6b6-451e-a9cf-5ad250f78158",
   "metadata": {},
   "source": [
    "#### Register step\n",
    "The register step creates a SageMaker model and registers a new version of a model in the SageMaker Model Registry within a [model package group](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-model-group.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a852b5a-1c58-4d3b-acd4-d4f8803a3029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    image_uri=LinearRegression_image_uri,        \n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    name=f\"Solar-energy-regression-model\",\n",
    "    sagemaker_session=session,\n",
    "    role=sm_role,\n",
    ")\n",
    "\n",
    "...................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdccd244-757c-4dfc-b18b-0b6d84ef22a5",
   "metadata": {},
   "source": [
    "#### Fail step\n",
    "Add a Pipelines [FailStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.fail_step.FailStep) to stop the pipeline execution if the model performance metric doesn't meet the specified threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba5b9b2-2faa-473b-ae18-96b6c33f41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_fail = FailStep(\n",
    "    name=f\"{pipeline_name}-fail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to AUC Score >\", test_score_threshold_param]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c23cb03-6a6d-4f3c-a665-6ba7b2814cb3",
   "metadata": {},
   "source": [
    "#### Condition step\n",
    "The condition step checks the model performance score and conditionally creates a model and registers it in the model registry, or stops and fails the pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356cb055-d2c0-4e0e-8407-d1b93b4911e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_lte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.rmse.value\",\n",
    "    ),\n",
    "    right=test_score_threshold_param,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=f\"{pipeline_name}-check-test-score\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5812b7-8e62-46d0-9763-6a15018671c2",
   "metadata": {},
   "source": [
    "#### Construct the pipeline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68130a-2c62-4078-80cc-7391d1eaa217",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,...................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02b390-ed80-4967-b704-188a83bf7931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new or update existing Pipeline\n",
    "pipeline.upsert(role_arn=sm_role.expr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b75a822-cedb-40f4-91ff-c153f86f962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_definition = json.loads(pipeline.describe()['PipelineDefinition'])\n",
    "pipeline_definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f30054b-3a8b-48e9-ad6e-2f2e8ddb8ec1",
   "metadata": {},
   "source": [
    "## Execute the pipeline\n",
    "The following code starts an execution of the pipeline with the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b60cb-060a-4829-944a-a3fcce2c8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=process_instance_type,\n",
    "        TrainingInstanceType=train_instance_type,\n",
    "        TrainingInstanceCount=train_instance_count,\n",
    "        ModelApprovalStatus=\"PendingManualApproval\",\n",
    "        TestScoreThreshold=0.75,\n",
    "        InputDataUrl=input_s3_url\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea8c82-c2e7-415c-8c6e-bae6355a0b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-comment this call if you want the notebook to wait until the pipeline's execution finished\n",
    "execution.wait()\n",
    "execution.list_steps()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
